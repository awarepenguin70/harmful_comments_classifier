# ğŸš¨ Harmful Comment Classification System  

## ğŸ“Œ Overview  
This project aims to automatically **detect and classify harmful or offensive comments** on social media platforms using **Natural Language Processing (NLP)** and **Machine Learning (ML)**. It compares two classification modelsâ€”**NaÃ¯ve Bayes (MultinomialNB)** and **k-Nearest Neighbors (k-NN)**â€”to determine which performs better in identifying toxic content.

---

## ğŸ” Key Features  
âœ”ï¸ **Text Preprocessing** â€“ Cleans and normalizes raw text data  
âœ”ï¸ **Feature Extraction** â€“ Uses TF-IDF and Count Vectorization  
âœ”ï¸ **Model Comparison** â€“ Evaluates NaÃ¯ve Bayes vs. k-NN  
âœ”ï¸ **Performance Metrics** â€“ Accuracy, Precision, Recall, F1-Score  
âœ”ï¸ **Visual Insights** â€“ Confusion Matrix, ROC Curves, Word Clouds  

---

## ğŸ› ï¸ Installation & Setup  
### Prerequisites  
- Python 3.8+  
- Required packages in `requirements.txt`  

---

## ğŸ“Š Algorithms & How They Work  

### 1ï¸âƒ£ Text Preprocessing  
Before feeding text into ML models, the following steps are applied:  
- **Lowercasing:** Converts text to lowercase (e.g., "You're STUPID" â†’ "you're stupid")  
- **Removing URLs & Special Characters:** Eliminates irrelevant symbols  
- **Stopword Removal:** Removes common words like "the," "and," "is"  
- **Tokenization & Stemming:** Converts words to base forms (e.g., "running" â†’ "run")  

---

### 2ï¸âƒ£ Feature Extraction  
Text is converted into numerical features using:  
- **TF-IDF (Term Frequency-Inverse Document Frequency)**  
   - Weighs words by importance in a document vs. corpus  
   - Identifies rare but significant toxic terms (e.g., "kill," "worthless")  

- **Count Vectorization**  
   - Simple word frequency count  
   - Useful for detecting common toxic phrases  

---

### 3ï¸âƒ£ Machine Learning Models  

#### ğŸ”¹ NaÃ¯ve Bayes (MultinomialNB)  
- **How it works:**  
   - Uses Bayes' Theorem to predict class probabilities  
   - Treats each word as an independent feature (bag-of-words)  

- âœ… **Pros:**  
   - Fast training & prediction  
   - Effective with high-dimensional text data  

- â—ï¸ **Cons:**  
   - Struggles with word dependencies (e.g., sarcasm)  

---

#### ğŸ”¹ k-Nearest Neighbors (k-NN)  
- **How it works:**  
   - Classifies comments based on similarity to nearest training examples  
   - Uses Euclidean distance in vector space  

- âœ… **Pros:**  
   - No training required (lazy learning)  
   - Adapts to new patterns in data  

- â—ï¸ **Cons:**  
   - Slower at prediction time  
   - Sensitive to imbalanced datasets  

---

## ğŸ“ˆ Performance Comparison  

| Model                  | Accuracy | Precision | Recall | F1-Score |
|------------------------|----------|-----------|--------|----------|
| NaÃ¯ve Bayes (TF-IDF)    | 86.4%    | 100%      | 66.7%  | 80.0%    |
| k-NN (TF-IDF)           | 95.5%    | 90%       | 100%   | 94.7%    |
| NaÃ¯ve Bayes (Count)     | 95.5%    | 100%      | 88.9%  | 94.1%    |
| k-NN (Count)            | 63.6%    | 100%      | 11.1%  | 20.0%    |

---

## ğŸ¯ Key Takeaways  
âœ… **Best Model:** NaÃ¯ve Bayes with Count Vectorization (95.5% accuracy, 94.1% F1-Score)  
âœ… **Best for Precision:** NaÃ¯ve Bayes (100% precision) â€“ No false positives  
âœ… **Best for Recall:** k-NN with TF-IDF (100% recall) â€“ Catches all harmful comments  

---

## ğŸš€ Future Improvements  
ğŸ”¸ **Add Deep Learning:** Implement BERT, LSTM for better contextual understanding  
ğŸ”¸ **Expand Dataset:** Include sarcasm, slang, and multilingual comments  
ğŸ”¸ **Real-Time API:** Build an API for live comment moderation  
ğŸ”¸ **Bias Mitigation:** Reduce false positives for minority dialects  

---

## ğŸ“œ License  
This project is open-source under the **MIT License**.  

---

## ğŸ“¬ Contact  
For questions or contributions, reach out:  
ğŸ“§ **Email:** [rahul004prasad@gmail.com](mailto:rahul004prasad@gmail.com)  
ğŸŒ **GitHub:** [awarepenguin70](https://github.com/awarepenguin70)  

---

## ğŸ“ Conclusion  
This system provides a strong baseline for harmful comment detection and can be deployed in moderation pipelines. While NaÃ¯ve Bayes performs best, future work should focus on improving recall for nuanced toxicity.
