Harmful Comment Classification System
ğŸ“Œ Overview
This project aims to automatically detect and classify harmful or offensive comments on social media platforms using Natural Language Processing (NLP) and Machine Learning (ML). It compares two classification modelsâ€”NaÃ¯ve Bayes (MultinomialNB) and k-Nearest Neighbors (k-NN)â€”to determine which performs better in identifying toxic content.

ğŸ” Key Features
âœ” Text Preprocessing â€“ Cleans and normalizes raw text data
âœ” Feature Extraction â€“ Uses TF-IDF and Count Vectorization
âœ” Model Comparison â€“ Evaluates NaÃ¯ve Bayes vs. k-NN
âœ” Performance Metrics â€“ Accuracy, Precision, Recall, F1-Score
âœ” Visual Insights â€“ Confusion Matrix, ROC Curves, Word Clouds

ğŸ›  Installation & Setup
Prerequisites
Python 3.8+


ğŸ“Š Algorithms & How They Work
1. Text Preprocessing
   Before feeding text into ML models, we clean it using:

Lowercasing ("You're STUPID" â†’ "you're stupid")

Removing URLs & Special Characters

Stopword Removal ("the", "and", "is")

Tokenization & Stemming ("running" â†’ "run")

2. Feature Extraction
   Text is converted into numerical features using:

TF-IDF (Term Frequency-Inverse Document Frequency)

Weights words by importance in a document vs. corpus

Helps identify rare but significant toxic terms (e.g., "kill", "worthless")

Count Vectorization

Simple word frequency count

Useful for detecting common toxic phrases

3. Machine Learning Models
   ğŸ”¹ NaÃ¯ve Bayes (MultinomialNB)
   How it works:

Uses Bayes' Theorem to predict class probabilities

Treats each word as an independent feature (bag-of-words)

Pros:

Fast training & prediction

Works well with high-dimensional text data

Cons:

Struggles with word dependencies (e.g., sarcasm)

ğŸ”¹ k-Nearest Neighbors (k-NN)
How it works:

Classifies comments based on similarity to nearest training examples

Uses Euclidean distance in vector space

Pros:

No training required (lazy learning)

Adapts to new patterns in data

Cons:

Slower at prediction time

Sensitive to imbalanced datasets

ğŸ“ˆ Performance Comparison
Model	Accuracy	Precision	Recall	F1-Score
NaÃ¯ve Bayes (TF-IDF)	86.4%	100%	66.7%	80.0%
k-NN (TF-IDF)	95.5%	90%	100%	94.7%
NaÃ¯ve Bayes (Count)	95.5%	100%	88.9%	94.1%
k-NN (Count)	63.6%	100%	11.1%	20.0%
Key Takeaways
âœ… Best Model: NaÃ¯ve Bayes with Count Vectorization (95.5% accuracy, 94.1% F1)
âœ… Best for Precision: NaÃ¯ve Bayes (100% precision) â€“ No false positives
âœ… Best for Recall: k-NN with TF-IDF (100% recall) â€“ Catches all harmful comments

ğŸš€ Future Improvements
Add Deep Learning (BERT, LSTM) for better contextual understanding

Expand Dataset to include sarcasm, slang, and multilingual comments

Real-Time API for live comment moderation

Bias Mitigation to reduce false positives in minority dialects

ğŸ“œ License
This project is open-source under the MIT License.

ğŸ“¬ Contact
For questions or contributions, reach out:
ğŸ“§ Email: rahul004prasad@gmail.com
ğŸŒ GitHub: https://github.com/awarepenguin70

ğŸ¯ Conclusion
This system provides a strong baseline for harmful comment detection and can be deployed in moderation pipelines. While NaÃ¯ve Bayes performs best, future work should focus on improving recall for nuanced toxicity.